{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85befc0-6ecd-4df7-b31e-b444753ef83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "code to retrieve CO slabs/profiles of near-IR NIRSPEC observations. Use slabspec initial fits as first guesses for retrievals\n",
    "For now, retrieving the inner and outer temp and column density and emitting area (5 variables total), and assumes that they decay as a power law\n",
    "assumes r_in = 0.1 amd r_out = 10.0 (also for now).\n",
    "!! marks to-do items or hard-coded things\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "import pickle as pickle\n",
    "import os as os\n",
    "import pandas as pd\n",
    "from astropy.table import Table, vstack, QTable\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "import sys\n",
    "import iris as iris\n",
    "from iris import setup\n",
    "import time\n",
    "from utils import * # !! are there different utils i need here?\n",
    "\n",
    "# retrievals:\n",
    "from dynesty import NestedSampler\n",
    "import scipy.stats as stats\n",
    "import pickle\n",
    "import dynesty.plotting as dyplot\n",
    "import dynesty.utils as dyfunc\n",
    "from corner import corner\n",
    "\n",
    "# Queries - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "radial_profile = 0 # if 0: will retrieve a slab model w/ a single component. if 1: will retrieve a radial profile as defined below\n",
    "forward_model_query = 0 # if 0: will run full retrieval. if 1: will only generate forward model using initial inputs\n",
    "keplerian_query = 1 # if 0: will use normal slab.simulate. if 1: will apply keplerian broadening\n",
    "CO_12 = 1 # if 1: will model 12CO. if 0: will not\n",
    "CO_13 = 0 # if 1: will model 13CO. if 0: will not\n",
    "\n",
    "corner_plot_query = 1 # 1, will make corner plot of retrieval results; 0, will not\n",
    "plot_results_query = 1 # 1, will plot measured and fit fluxes; 0, will not\n",
    "\n",
    "if forward_model_query == 1:\n",
    "    corner_plot_query = 0 # won't plot retrieval-assessing plots if only doing a forward model\n",
    "\n",
    "# !! need a conditional here for dimensions\n",
    "ndim = 5 # dimensions; number of free parameters (number of free parameters, called in NestedSampler) !! make this automatic?\n",
    "dlogz = 0.1  # termination condition (called in NestedSampler)\n",
    "\n",
    "cont_jy = 0.95 # continuum level in Jy. Should be ~1 for most nirspec data??\n",
    "R = 37500 # for NIRSPEC\n",
    "\n",
    "# filenames and paths - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "source_name = 'FZTau'\n",
    "input_file = np.loadtxt('./'+source_name+'_output_0', dtype=str)\n",
    "name_for_files = 'retrieval_nirspec_test_'+source_name\n",
    "checkpoint_file = '/home/dahlek/prima/retrievals/pickle_files/'+name_for_files+'.save' # file to use as \n",
    "figure_directory = '/home/dahlek/prima/retrievals/figures/nirspec/' # save figures here\n",
    "pickle_file = checkpoint_file[:-5]\n",
    "figure_name = np.copy(name_for_files)\n",
    "path_to_moldata = '/home/dahlek/HITRAN_data'\n",
    "path_to_data = '/home/dahlek/spectra/'+source_name+'_fullstack.csv'\n",
    "\n",
    "# load data and info - - - - - - - - - - \n",
    "# Load a continuum-subtracted spectrum\n",
    "infile=Table.read(path_to_data, format='ascii')\n",
    "df=infile.to_pandas()\n",
    "wavelength = np.array(df['wave']) # obs_wgrid\n",
    "flux = np.array(df['flux']-cont_jy) # subtract continuum? seems to be normalized to 1\n",
    "error = np.array(df['uflux'])\n",
    "wmin = np.min(wavelength); wmax = np.max(wavelength)\n",
    "\n",
    "wl, flux_ignore, flux_error, wl_min, wl_max, wl_min_intermediate, wl_max_intermediate = readin(path_to_data)\n",
    "\n",
    "# make a flux and wavelength array that ignores the nan values present in original dataset\n",
    "no_nan_locations = np.where(np.isnan(flux) == False)[0]\n",
    "flux_without_nans = flux[no_nan_locations]; wavelength_without_nans = wavelength[no_nan_locations]; error_without_nans = error[no_nan_locations]\n",
    "flux = np.copy(flux_without_nans); wavelength = np.copy(wavelength_without_nans); error = np.copy(error_without_nans)\n",
    "\n",
    "fine_wgrid = np.arange(wmin-0.1 , wmax+0.1, 1e-5) # define a wavelength grid\n",
    "\n",
    "\n",
    "# inputs from slabspec and variables specific to disk - - - - - - - - - - -\n",
    "\n",
    "# if CO_12 == 1:\n",
    "# if 12CO is turned out, load input file as if it were 12CO data\n",
    "# if we run simultaneous retrievals w/ different species later, will want to label these w/ CO specifically. for now, we're doing one at a time so leave the variable names more generic\n",
    "source_name = input_file[0]\n",
    "distance = float(input_file[1]) # pc\n",
    "inc = float(input_file[2]) # deg\n",
    "M_star = float(input_file[3]) # M_solar\n",
    "# high J values\n",
    "logN_high, logN_perr_high, logN_nerr_high, T_high, T_perr_high, T_nerr_high, logOmega_high, logOmega_perr_high, logOmega_nerr_high = input_file[4:13]\n",
    "logN_low, logN_perr_low, logN_nerr_low, T_low, T_perr_low, T_nerr_low, logOmega_low, logOmega_perr_low, logOmega_nerr_low = input_file[13:22]\n",
    "logN_all, logN_perr_all, logN_nerr_all, T_all, T_perr_all, T_nerr_all, logOmega_all, logOmega_perr_all, logOmega_nerr_all = input_file[22:31]\n",
    "# rename and organize to work with preexisting iris script\n",
    "log_T_slabspec_high = np.log10(T_high); log_T_slabspec_low = np.log10(T_low); log_T_slabspec_all = np.log10(T_all)\n",
    "log_N_slabspec_high = logN_high-4; log_N_slabspec_low = logN_low-4; log_N_slabspec_all = logN_all-4 # !! subtracting 4 is converting m^-2 to cm^-2 in log space\n",
    "# convert solid angle in radians to square AU\n",
    "omega_high = 10**logOmega_high; omega_low = 10**logOmega_low; omega_all = 10**logOmega_all\n",
    "log_area_au_high = np.log10(calc_radius(omega_high, distance)**2); log_area_au_low = np.log10(calc_radius(omega_low, distance)**2); log_area_au_all = np.log10(calc_radius(omega_all, distance)**2); \n",
    "\n",
    "dV_slabspec_CO = 2 # want to sample the line well enough\n",
    "dV_slabspec_13CO = 2\n",
    "\n",
    "# molecule information: - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# can add more conditionals here for other molecules\n",
    "if CO_12 == 1 and CO_13 == 0:\n",
    "    list_of_molecules = ['CO']\n",
    "    #setup.setup_linelists('CO', 'CO', 1, path_to_moldata)\n",
    "elif CO_12 == 1 and CO_13 == 1:\n",
    "    list_of_molecules = ['CO','13CO']\n",
    "    #setup.setup_linelists('CO', 'CO', 1, path_to_moldata)\n",
    "    #setup.setup_linelists('13CO', 'CO', 2, path_to_moldata)\n",
    "elif CO_12 == 0 and CO_13 == 1:\n",
    "    list_of_molecules = ['13CO']\n",
    "    #setup.setup_linelists('13CO', 'CO', 2, path_to_moldata)\n",
    "\n",
    "\n",
    "# initiate slab - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "slab = iris.slab(molecules=list_of_molecules, wlow=wmin-0.5, whigh=wmax+0.5, path_to_moldata=path_to_moldata)\n",
    "\n",
    "if keplerian_query == 0:\n",
    "    def compiled_slab(distance, T_ex, N_mol, A_au, dV, fine_wgrid, wavelength, R):\n",
    "        slab.setup_disk(distance, T_ex, N_mol, A_au, dV) # initialize object\n",
    "        slab.setup_grid(fine_wgrid, wavelength, R) # set up wavelength and model parameters\n",
    "        slab.simulate() # make model\n",
    "        return slab.downsampled_flux\n",
    "\n",
    "elif keplerian_query == 1: # output shape will need to be added as an input here, and everywhere else compiled_slab is called\n",
    "    def compiled_slab(distance, T_ex, N_mol, A_au, dV, r_in, M_star, inc, fine_wgrid, wavelength, R):\n",
    "        slab.setup_disk(distance, T_ex, N_mol, A_au, dV, inc, M_star, r_in) # initialize object\n",
    "        slab.setup_grid(fine_wgrid, wavelength, R) # set up wavelength and model parameters\n",
    "        slab.simulate_keplerian() # make model\n",
    "        return slab.downsampled_flux\n",
    "\n",
    "compiled_slab_jit = jax.jit(compiled_slab)\n",
    "\n",
    "\n",
    "# define slab model, along with temp and column density profiles, etc. - - - - - - - - -\n",
    "\n",
    "def N_powerlaw(r, N_in, N_out, r_in=0.1, r_out=10.0):\n",
    "    '''\n",
    "    Uses innermost and outermost column densities to calculate a power law\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    r : float\n",
    "        radius value in AU. plug in rgrid here\n",
    "    N_in, N_out : \n",
    "        column densities from high- and low-energy lines, respectively **not log**\n",
    "    r_in and r_out : \n",
    "        inner and outer boundary of disk in AU\n",
    "        \n",
    "    Returns\n",
    "    -----------\n",
    "    k*r**a : array, float\n",
    "        column density power law over radius values r\n",
    "    '''   \n",
    "    a = (np.log10(N_out)-np.log10(N_in))/(np.log10(r_out)-np.log10(r_in)) # a = (log(y2) - log(y1)) / (log(x2) - log(x1)) # exponent\n",
    "    k = N_in/(r_in**a) # k = y1 / (x1^a) # factor\n",
    "\n",
    "    return k*r**a\n",
    "\n",
    "def T_powerlaw(r, T_in, T_out, r_in=0.1, r_out=10.0):\n",
    "    '''\n",
    "    Uses innermost and outermost column densities to calculate a power law\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    r : float\n",
    "        radius value in AU. plug in rgrid here\n",
    "    T_in, T_out : \n",
    "        temperatures from high- and low-energy lines, respectively **not log**\n",
    "    r_in and r_out : \n",
    "        inner and outer boundary of disk in AU\n",
    "        \n",
    "    Returns\n",
    "    -----------\n",
    "    k*r**a : array, float\n",
    "        temp power law over radius values r\n",
    "    '''\n",
    "    a = (np.log10(T_out)-np.log10(T_in))/(np.log10(r_out)-np.log10(r_in)) # a = (log(y2) - log(y1)) / (log(x2) - log(x1)) # exponent\n",
    "    k = T_in/(r_in**a) # k = y1 / (x1^a) # factor\n",
    "\n",
    "    return k*r**a\n",
    "\n",
    "def make_annuli(npoints, rin, rout, inc):\n",
    "    '''\n",
    "    Input: the number of radial points, innermost radius (au), outermost radius (au), and disk inclination (deg)\n",
    "    Output the grid of AREAS of each annulus (au2), and the grid of RADII (au) at the center of each annulus\n",
    "    '''\n",
    "    rlow = np.logspace(np.log10(rin), np.log10(rout), npoints+1)\n",
    "    dr = []\n",
    "    for i,r in enumerate(rlow):\n",
    "      try:\n",
    "        dr.append(rlow[i+1] - rlow[i])\n",
    "      except:\n",
    "        continue\n",
    "\n",
    "    dr = jnp.array(dr) # r bin spacing\n",
    "    rgrid = rlow[0:npoints] + dr/2 # r where T,N will be calculated\n",
    "\n",
    "    Agrid = jnp.pi * np.cos(inc*np.pi/180) * (((rlow[0:npoints]+dr)**2) - (rlow[0:npoints]**2))\n",
    "\n",
    "    return Agrid, rgrid\n",
    "\n",
    "\n",
    "# calculate values to make a forward model\n",
    "T_in = 10**log_T_slabspec_high ; T_out = 10**log_T_slabspec_low\n",
    "N_in = 10**log_N_slabspec_high ; N_out = 10**log_N_slabspec_low\n",
    "\n",
    "# Excitation temperatures for each molecule in K\n",
    "T_ex = jnp.array([  np.array([CO_12*T_powerlaw(j, T_in, T_out) for j in rgrid]),\n",
    "                    np.array([CO_13*T_powerlaw(j, T_in, T_out) for j in rgrid]) ]) # will need to replace N_powerlaw to something specific to 13CO\n",
    "# column densities in cm^-2\n",
    "N_mol = jnp.array([ np.array([CO_12*N_powerlaw(j, N_in, N_out) for j in rgrid]),\n",
    "                    np.array([CO_13*N_powerlaw(j, N_in, N_out) for j in rgrid]) ]) # will need to replace N_powerlaw to something specific to 13CO\n",
    "# emitting areas in au^2\n",
    "A_au =  np.array([ np.array([CO_12*10**log_area_au_all]),\n",
    "                   np.array([CO_13*10**log_area_au_all]) ])\n",
    "# fixed line widths in km/s (line FWHM)\n",
    "dV = np.array([ np.array([CO_12*dV_slabspec_CO]),\n",
    "                np.array([CO_13*dV_slabspec_13CO]) ])\n",
    "\n",
    "\n",
    "if keplerian_query == 0:\n",
    "    model = compiled_slab_jit(distance, T_ex, N_mol, A_au, dV, fine_wgrid, wavelength, R)\n",
    "elif keplerian_query == 1:\n",
    "    model = compiled_slab_jit(distance, T_ex, N_mol, A_au, dV, r_in, M_star, inc, fine_wgrid, wavelength, R)\n",
    "\n",
    "if len(model) != len(flux):\n",
    "    print('Warning!!! mismatch between number of model and flux data points.')\n",
    "\n",
    "\n",
    "# save the wavelength, measured flux, and modeled flux if you want to\n",
    "'''\n",
    "dummy = np.zeros((len(wavelength),3))\n",
    "dummy[:,0] = wavelength\n",
    "dummy[:,1] = flux\n",
    "dummy[:,2] = model\n",
    "np.savetxt('./forward_model_'+name_for_files, dummy)\n",
    "'''\n",
    "\n",
    "if plot_results_query == 1:\n",
    "    plt.plot(wavelength, flux, color='black', lw=0.5, label='data')\n",
    "    plt.fill_between(wavelength, model,  color='dodgerblue', alpha=0.6, label='model')\n",
    "\n",
    "    plt.xlim(wavelength.min()-0.01, wavelength.max()+0.01)\n",
    "    plt.ylabel('Flux density (Jy)')\n",
    "    plt.xlabel('Wavelength ($\\\\mu$m)')\n",
    "    plt.title('Forward model guess w/ data')\n",
    "\n",
    "    #plt.ylim(np.min(flux)-1e1, np.max(flux)+1e1 )\n",
    "    plt.legend()\n",
    "    plt.savefig(figure_directory+'initial_guess_model_spectrum_'+figure_name)\n",
    "    plt.show()\n",
    "\n",
    "if forward_model_query == 1:\n",
    "    sys.exit() # end the program if just running a forward model\n",
    "\n",
    "\n",
    "# begin setting up retrieval - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "# set up priors based on slabspec inputs\n",
    "# !! commenting out 13CO stuff for now\n",
    "\n",
    "# define test range for high N \n",
    "min_N_guess_high = log_N_slabspec_high-3.0\n",
    "max_N_guess_high = log_N_slabspec_high+3.0\n",
    "\n",
    "# define test range for low N \n",
    "min_N_guess_low = log_N_slabspec_low-3.0\n",
    "max_N_guess_low = log_N_slabspec_low+3.0\n",
    "\n",
    "# define test range for high T\n",
    "min_T_guess_high = log_T_slabspec_high-1.0\n",
    "max_T_guess_high = log_T_slabspec_high+1.0\n",
    "\n",
    "# define test range for low T \n",
    "min_T_guess_low = log_T_slabspec_low-1.0\n",
    "max_T_guess_low = log_T_slabspec_low+1.0\n",
    "\n",
    "#min_temp_guess_13CO = log_T_slabspec_13CO-1.0\n",
    "#max_temp_guess_13CO = log_T_slabspec_13CO+1.0-min_temp_guess_13CO\n",
    "\n",
    "min_area_guess = log_area_au_all-1.0\n",
    "max_area_guess = log_area_au_all+1.0-min_area_guess # for uniform prior\n",
    "\n",
    "#min_area_guess_13CO = log_area_au_13CO-1.0\n",
    "#max_area_guess_13CO = log_area_au_13CO+1.0-min_area_guess_13CO\n",
    "\n",
    "# !! need to add conditionals within ln_prior for modeling CO and/or 13CO. can I feed it values aside from uparams?\n",
    "def ln_prior(uparams):\n",
    "\n",
    "    '''\n",
    "    Dynesty samples from a unit cube, so we need to transform this to the range\n",
    "    of values we want for each free parameter.\n",
    "\n",
    "    e.g. For log Area, we go from U(0,1) ---->  U(-3, 3.0)\n",
    "         (so we are sampling area values from 0.001 to 1000.0)\n",
    "    '''\n",
    "    ulog_T_high, ulog_T_low, ulog_N_high, ulog_N_low, ulog_A = uparams \n",
    "\n",
    "    # Truncated Normal prior for log temperature, high energy\n",
    "    m, s = log_T_slabspec_high, 0.5 # mean and standard deviation\n",
    "    low, high = min_T_guess_high, max_T_guess_high  # lower and upper bounds\n",
    "    low_n, high_n = (low - m) / s, (high - m) / s  # standardize\n",
    "    log_T_high = stats.truncnorm.ppf(ulog_T_high, low_n, high_n, loc=m, scale=s)\n",
    "    \n",
    "    # Truncated Normal prior for log temperature, low energy\n",
    "    m, s = log_T_slabspec_low, 0.5 # mean and standard deviation\n",
    "    low, high = min_T_guess_low, max_T_guess_low  # lower and upper bounds\n",
    "    low_n, high_n = (low - m) / s, (high - m) / s  # standardize\n",
    "    log_T_low = stats.truncnorm.ppf(ulog_T_low, low_n, high_n, loc=m, scale=s)\n",
    "    \n",
    "    # Truncated Normal prior for log column density, high energy\n",
    "    m, s = log_N_slabspec_high, 1.5 # mean and standard deviation\n",
    "    low, high = min_N_guess_high, max_N_guess_high  # lower and upper bounds\n",
    "    low_n, high_n = (low - m) / s, (high - m) / s  # standardize\n",
    "    log_N_high = stats.truncnorm.ppf(ulog_N_high, low_n, high_n, loc=m, scale=s)\n",
    "    \n",
    "    # Truncated Normal prior for log column density, low energy\n",
    "    m, s = log_N_slabspec_low, 1.5 # mean and standard deviation\n",
    "    low, high = min_N_guess_low, max_N_guess_low  # lower and upper bounds\n",
    "    low_n, high_n = (low - m) / s, (high - m) / s  # standardize\n",
    "    log_N_low = stats.truncnorm.ppf(ulog_N_low, low_n, high_n, loc=m, scale=s)\n",
    "\n",
    "    # Uniform prior for log area U(-3.0, 3.0) # !! hard-coded guess range for area\n",
    "    log_A = min_area_guess + ulog_A * max_area_guess\n",
    "\n",
    "    return log_T_high, log_T_low, log_N_high, log_N_low, log_A\n",
    "\n",
    "\n",
    "\n",
    "# LOG LIKELIHOOD\n",
    "def ln_like(params, wavelength=wavelength, flux=flux, error=error, keplerian_query=keplerian_query, inc=inc, M_star=M_star, CO_12=CO_12, CO_13=CO_13):\n",
    "    log_T_high, log_T_low, log_N_high, log_N_low, log_A = params\n",
    "\n",
    "    '''Set up the disk model'''\n",
    "    T_in = 10**log_T_high ; T_out = 10**log_T_low\n",
    "    N_in = 10**log_N_high ; N_out = 10**log_N_low\n",
    "    \n",
    "    # Excitation temperatures for each molecule in K\n",
    "    T_ex = jnp.array([  np.array([CO_12*T_powerlaw(j, T_in, T_out) for j in rgrid]),\n",
    "                        np.array([CO_13*T_powerlaw(j, T_in, T_out) for j in rgrid]) ]) # will need to replace T_powerlaw to something specific to 13CO\n",
    "    # column densities in cm^-2\n",
    "    N_mol = jnp.array([ np.array([CO_12*N_powerlaw(j, N_in, N_out) for j in rgrid]),\n",
    "                        np.array([CO_13*N_powerlaw(j, N_in, N_out) for j in rgrid]) ]) # will need to replace N_powerlaw to something specific to 13CO\n",
    "    # emitting areas in au^2\n",
    "    A_au =  np.array([ np.array([CO_12*10**log_area_au_all]),\n",
    "                       np.array([CO_13*10**log_area_au_all]) ])\n",
    "    # fixed line widths in km/s (line FWHM)\n",
    "    dV = np.array([ np.array([CO_12*dV_slabspec_CO]),\n",
    "                    np.array([CO_13*dV_slabspec_13CO]) ])\n",
    "\n",
    "    # can add print statement for variables here\n",
    "    if keplerian_query == 0:\n",
    "        model = compiled_slab_jit(distance, T_ex, N_mol, A_au, dV, fine_wgrid, wavelength, R)\n",
    "    elif keplerian_query == 1:\n",
    "        model = compiled_slab_jit(distance, T_ex, N_mol, A_au, dV, r_in, M_star, inc, fine_wgrid, wavelength, R)\n",
    "    print('log_T_high, log_T_low, log_N_high, log_N_low, log_A ', log_T_high, log_T_low, log_N_high, log_N_low, log_A )\n",
    "    print('log liklihood',- np.nansum( 1/(2*(error**2)) * ((flux - model)**2) ))\n",
    "    return - np.nansum( 1/(2*(error**2)) * ((flux - model)**2) )\n",
    "\n",
    "\n",
    "\n",
    "# Set up the Nested Sampler - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "print('Setting up the Nested Sampler...')\n",
    "dsampler = NestedSampler(ln_like, ln_prior, ndim=ndim,\n",
    "                             bound='multi', sample='rwalk', nlive=20*ndim)\n",
    "\n",
    "# Run retrieval - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "print('Running retrieval...')\n",
    "\n",
    "dsampler.run_nested(dlogz=dlogz, maxcall=2e6,\n",
    "                    checkpoint_file=checkpoint_file, checkpoint_every=600,\n",
    "                    print_progress=True)\n",
    "\n",
    "# Get the results, save - - - - - - - - - - - - - - - - - - - - - - \n",
    "dres = dsampler.results\n",
    "\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(dres, f)\n",
    "\n",
    "\n",
    "# Get the WEIGHTED samples - - - - - - - - - - - - - - - - - - - - -\n",
    "weights = dres.importance_weights()\n",
    "wsamps = dyfunc.resample_equal(dres.samples, weights)\n",
    "\n",
    "mean = np.mean(wsamps, axis=0)\n",
    "std = np.std(wsamps, axis=0)\n",
    "\n",
    "# pull T, N, A, and power laws for best-fit model: - - - - - - - - - - - - - - \n",
    "\n",
    "log_T_high, log_T_low, log_N_high, log_N_low, log_A = mean[0], mean[1], mean[2], mean[3], mean[4]\n",
    "# add lines here for 13CO or other molecules\n",
    "\n",
    "print('Best fit log T (high energy) =', round(mean[0],2), \"+-\", round(3*std[0], 4))\n",
    "print('Best fit log T (low energy) =', round(mean[1],2), \"+-\", round(3*std[1], 4))\n",
    "print('Best fit log N (high energy) =', round(mean[2],2), \"+-\", round(3*std[2], 4))\n",
    "print('Best fit log N (low energy) =', round(mean[3],2), \"+-\", round(3*std[3], 4))\n",
    "print('Best fit log A (12CO) =', round(mean[4],2), \"+-\", round(3*std[4], 4))\n",
    "\n",
    "r_in = 0.1; r_out = 10\n",
    "T_in = 10**log_T_high ; T_out = 10**log_T_low\n",
    "N_in = 10**log_N_high ; N_out = 10**log_N_low\n",
    "a_N = (np.log10(N_out)-np.log10(N_in))/(np.log10(r_out)-np.log10(r_in)) # a = (log(y2) - log(y1)) / (log(x2) - log(x1)) # exponent\n",
    "k_N = N_in/(r_in**a) # k = y1 / (x1^a) # factor\n",
    "print('Col density power law: N(r) =', str(k_N),'r^',a_N)\n",
    "a_T = (np.log10(T_out)-np.log10(T_in))/(np.log10(r_out)-np.log10(r_in)) # a = (log(y2) - log(y1)) / (log(x2) - log(x1)) # exponent\n",
    "k_T = T_in/(r_in**a) # k = y1 / (x1^a) # factor\n",
    "print('Temperature power law: T(r) =', str(k_T),'r^',a_T)\n",
    "\n",
    "\n",
    "# Excitation temperatures for each molecule in K\n",
    "T_ex = jnp.array([  np.array([CO_12*T_powerlaw(j, T_in, T_out) for j in rgrid]),\n",
    "                    np.array([CO_13*T_powerlaw(j, T_in, T_out) for j in rgrid]) ]) # will need to replace N_powerlaw to something specific to 13CO\n",
    "# column densities in cm^-2\n",
    "N_mol = jnp.array([ np.array([CO_12*N_powerlaw(j, N_in, N_out) for j in rgrid]),\n",
    "                    np.array([CO_13*N_powerlaw(j, N_in, N_out) for j in rgrid]) ]) # will need to replace N_powerlaw to something specific to 13CO\n",
    "# emitting areas in au^2\n",
    "A_au =  np.array([ np.array([CO_12*10**log_A]),\n",
    "                   np.array([CO_13*10**log_A]) ])\n",
    "# fixed line widths in km/s (line FWHM)\n",
    "dV = np.array([ np.array([CO_12*dV_slabspec_CO]),\n",
    "                np.array([CO_13*dV_slabspec_13CO]) ])\n",
    "\n",
    "# generate slab model using best-fit results\n",
    "if keplerian_query == 0:\n",
    "    bfmodel = compiled_slab_jit(distance, T_ex, N_mol, A_au, dV, fine_wgrid, wavelength, R)\n",
    "elif keplerian_query == 1:\n",
    "    bfmodel = compiled_slab_jit(distance, T_ex, N_mol, A_au, dV, r_in, M_star, inc, fine_wgrid, wavelength, R)\n",
    "\n",
    "\n",
    "# plot results - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "if plot_results_query == 1:\n",
    "    # !! need to break this into two subplots w/ intermediate wl breaking it up\n",
    "    plt.figure(figsize=(17,3))\n",
    "    plt.step(wavelength, flux, color='black', lw=0.5, label='data')\n",
    "    plt.fill_between(wavelength, bfmodel, color='dodgerblue', alpha=0.6, label='best fit model')\n",
    "\n",
    "    plt.xlim(wavelength.min(), wavelength.max())\n",
    "    plt.ylabel('Flux (Jy)')\n",
    "    plt.xlabel('Wavelength ($\\\\mu$m)')\n",
    "    plt.title('Test retrieval - FZ Tau')\n",
    "\n",
    "    #plt.ylim(-0.02, 0.2)\n",
    "    plt.legend()\n",
    "    plt.savefig(figure_directory+'model_spectrum_'+name_for_files)\n",
    "\n",
    "if plot_results_query == 1:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(rgrid, T_powerlaw(rgrid, T_in, T_out))\n",
    "    plt.title('Temperature profile')\n",
    "    plt.ylabel('Temperature (K)')\n",
    "    plt.xlabel('Radius (AU)')\n",
    "    plt.text(rgrid[-5], (T_in-T_out)/2, 'T(r) = '+str(k_T)+' r^'+str(a_T))\n",
    "    plt.savefig(figure_directory+'temp_profile_'+name_for_files)\n",
    "\n",
    "if plot_results_query == 1:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(rgrid, N_powerlaw(rgrid, N_in, N_out))\n",
    "    plt.title('Column density profile')\n",
    "    plt.ylabel('Column density cm^-2')\n",
    "    plt.xlabel('Radius (AU)')\n",
    "    plt.text(rgrid[-5], (N_in-N_out)/2, 'N(r) = '+str(k_N)+' r^'+str(a_N))\n",
    "    plt.savefig(figure_directory+'coldens_profile_'+name_for_files)\n",
    "    \n",
    "if corner_plot_query == 1:\n",
    "    dyplot.cornerplot(dres, labels=['log_T', 'log_N', 'log_A'], label_kwargs={'fontsize':15})\n",
    "    plt.savefig(figure_directory+'corner_plot_'+figure_name)\n",
    "\n",
    "# trace plot\n",
    "if corner_plot_query == 1:\n",
    "    dyplot.traceplot(dres, labels=['log_T', 'log_N', 'log_A'], label_kwargs={'fontsize':15})\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figure_directory+'trace_plot_'+figure_name)\n",
    "                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c43b1-d37c-496c-999e-1db73e4a4750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
